{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1b89a5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-04T16:06:59.802952Z",
     "iopub.status.busy": "2022-12-04T16:06:59.802511Z",
     "iopub.status.idle": "2022-12-04T16:06:59.839081Z",
     "shell.execute_reply": "2022-12-04T16:06:59.838190Z"
    },
    "papermill": {
     "duration": 0.048342,
     "end_time": "2022-12-04T16:06:59.841869",
     "exception": false,
     "start_time": "2022-12-04T16:06:59.793527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/27-11-filtering-columns-date-new/__results__.html\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__notebook__.ipynb\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__output__.json\n",
      "/kaggle/input/27-11-filtering-columns-date-new/custom.css\n",
      "/kaggle/input/27-11-filtering-columns-date-new/full_data_to_use_27-11.csv\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___80_0.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___50_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___9_0.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___38_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___121_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___104_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___84_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___54_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___61_0.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___14_0.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___70_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___77_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___110_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___62_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___113_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___86_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___49_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___73_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___48_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___43_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___69_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___112_2.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___16_0.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___65_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___82_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___59_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___46_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___91_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___74_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___88_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___107_1.png\n",
      "/kaggle/input/27-11-filtering-columns-date-new/__results___files/__results___101_1.png\n",
      "/kaggle/input/datacon-22/Processed_data/bookings.csv\n",
      "/kaggle/input/datacon-22/Processed_data/hotels_data.csv\n",
      "/kaggle/input/datacon-22/Processed_data/bookings_data.csv\n",
      "/kaggle/input/datacon-22/Processed_data/train_data.csv\n",
      "/kaggle/input/datacon-22/Processed_data/customer_data.csv\n",
      "/kaggle/input/datacon-22/Processed_data/sample_submission_5.csv\n",
      "/kaggle/input/datacon-22/Processed_data/payments_data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113438de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:06:59.857071Z",
     "iopub.status.busy": "2022-12-04T16:06:59.856812Z",
     "iopub.status.idle": "2022-12-04T16:07:04.633701Z",
     "shell.execute_reply": "2022-12-04T16:07:04.632675Z"
    },
    "papermill": {
     "duration": 4.786636,
     "end_time": "2022-12-04T16:07:04.636143",
     "exception": false,
     "start_time": "2022-12-04T16:06:59.849507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.optim as torch_optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecf1c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:04.651777Z",
     "iopub.status.busy": "2022-12-04T16:07:04.650761Z",
     "iopub.status.idle": "2022-12-04T16:07:04.773646Z",
     "shell.execute_reply": "2022-12-04T16:07:04.772621Z"
    },
    "papermill": {
     "duration": 0.133204,
     "end_time": "2022-12-04T16:07:04.776171",
     "exception": false,
     "start_time": "2022-12-04T16:07:04.642967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm # , # tqdm_notebook, # tnrange\n",
    "from tqdm.notebook import trange as tnrange # will change this to trange later \n",
    "from tqdm.notebook import tqdm as tqdm_notebook # will change this to tqdm later\n",
    "tqdm.pandas(desc='Progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80572ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:04.791148Z",
     "iopub.status.busy": "2022-12-04T16:07:04.790376Z",
     "iopub.status.idle": "2022-12-04T16:07:05.648197Z",
     "shell.execute_reply": "2022-12-04T16:07:05.647238Z"
    },
    "papermill": {
     "duration": 0.867825,
     "end_time": "2022-12-04T16:07:05.650834",
     "exception": false,
     "start_time": "2022-12-04T16:07:04.783009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/input/27-11-filtering-columns-date-new/full_data_to_use_27-11.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761da38",
   "metadata": {
    "papermill": {
     "duration": 0.007239,
     "end_time": "2022-12-04T16:07:05.664968",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.657729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Only 3 year values are there, so we map them to 1,2,3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0b6d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:05.681388Z",
     "iopub.status.busy": "2022-12-04T16:07:05.680481Z",
     "iopub.status.idle": "2022-12-04T16:07:05.720660Z",
     "shell.execute_reply": "2022-12-04T16:07:05.719738Z"
    },
    "papermill": {
     "duration": 0.050236,
     "end_time": "2022-12-04T16:07:05.723100",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.672864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data = { 2006:1,\n",
    "             2007:2,\n",
    "             2008:3}\n",
    "\n",
    "df['booking_checkin_customer_date_year'] = df['booking_checkin_customer_date_year'].map(new_data)\n",
    "df['booking_approved_at_year'] = df['booking_approved_at_year'].map(new_data)\n",
    "df['booking_create_timestamp_year'] = df['booking_create_timestamp_year'].map(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4524fb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:05.737328Z",
     "iopub.status.busy": "2022-12-04T16:07:05.736990Z",
     "iopub.status.idle": "2022-12-04T16:07:05.745554Z",
     "shell.execute_reply": "2022-12-04T16:07:05.744545Z"
    },
    "papermill": {
     "duration": 0.019301,
     "end_time": "2022-12-04T16:07:05.748852",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.729551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['booking_id',\n",
       " 'rating_score',\n",
       " 'set',\n",
       " 'booking_status',\n",
       " 'country',\n",
       " 'payment_type_mode',\n",
       " 'payment_type_count',\n",
       " 'payment_sequential_sum',\n",
       " 'payment_installments_count',\n",
       " 'payment_installments_sum',\n",
       " 'payment_value_count',\n",
       " 'booking_sequence_id_max',\n",
       " 'hotel_category_max',\n",
       " 'hotel_category_count',\n",
       " 'hotel_name_length_mean',\n",
       " 'hotel_photos_qty_mean',\n",
       " 'seller_agent_id_count',\n",
       " 'booking_create_timestamp_year',\n",
       " 'booking_create_timestamp_month',\n",
       " 'booking_create_timestamp_week',\n",
       " 'booking_create_timestamp_weekday',\n",
       " 'booking_create_timestamp_hour',\n",
       " 'booking_approved_at_year',\n",
       " 'booking_approved_at_month',\n",
       " 'booking_approved_at_week',\n",
       " 'booking_approved_at_weekday',\n",
       " 'booking_approved_at_hour',\n",
       " 'booking_checkin_customer_date_year',\n",
       " 'booking_checkin_customer_date_month',\n",
       " 'booking_checkin_customer_date_week',\n",
       " 'booking_checkin_customer_date_weekday',\n",
       " 'booking_checkin_customer_date_hour',\n",
       " 'payment_value_sum_log2',\n",
       " 'price_sum_log2',\n",
       " 'agent_fees_sum_log2',\n",
       " 'hotel_description_length_mean_log2',\n",
       " 'booking_approved_minus_created_days',\n",
       " 'booking_approved_minus_created_hours_log2',\n",
       " 'booking_checkin_minus_created_days_log2',\n",
       " 'booking_checkin_minus_created_hours_log2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = df.shape[1]\n",
    "features = list(df.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e210e4d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:05.762622Z",
     "iopub.status.busy": "2022-12-04T16:07:05.762369Z",
     "iopub.status.idle": "2022-12-04T16:07:05.767606Z",
     "shell.execute_reply": "2022-12-04T16:07:05.766781Z"
    },
    "papermill": {
     "duration": 0.014373,
     "end_time": "2022-12-04T16:07:05.769647",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.755274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def emb_init(x):\n",
    "    x = x.weight.data\n",
    "    sc = 2/(x.size(1)+1)\n",
    "    x.uniform_(-sc,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd76bf75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:05.783693Z",
     "iopub.status.busy": "2022-12-04T16:07:05.783414Z",
     "iopub.status.idle": "2022-12-04T16:07:05.791764Z",
     "shell.execute_reply": "2022-12-04T16:07:05.790707Z"
    },
    "papermill": {
     "duration": 0.018661,
     "end_time": "2022-12-04T16:07:05.794568",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.775907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('booking_status', 6), ('country', 9), ('payment_type_mode', 7.0)]\n",
      "[(6, 3), (9, 5), (7.0, 4.0)]\n"
     ]
    }
   ],
   "source": [
    "catf = ['booking_status',\n",
    " 'country',\n",
    " 'payment_type_mode',\n",
    "#  'booking_sequence_id_max',\n",
    "#  'hotel_category_count',\n",
    "#  'seller_agent_id_count',\n",
    "#  'booking_create_timestamp_year',\n",
    "#  'booking_create_timestamp_month',\n",
    "#  'booking_create_timestamp_week',\n",
    "#  'booking_create_timestamp_weekday',\n",
    "#  'booking_create_timestamp_hour',\n",
    "#  'booking_approved_at_year',\n",
    "#  'booking_approved_at_month',\n",
    "#  'booking_approved_at_weekday',\n",
    "#  'booking_checkin_customer_date_year',\n",
    "#  'booking_checkin_customer_date_month',\n",
    "#  'booking_checkin_customer_date_week',\n",
    "#  'booking_checkin_customer_date_weekday'\n",
    "       ]\n",
    "\n",
    "cat_sz = [(c, df[c].max()+1) for c in catf]\n",
    "print(cat_sz)\n",
    "\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]\n",
    "print(emb_szs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a8b2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:05.809626Z",
     "iopub.status.busy": "2022-12-04T16:07:05.809378Z",
     "iopub.status.idle": "2022-12-04T16:07:05.816375Z",
     "shell.execute_reply": "2022-12-04T16:07:05.815541Z"
    },
    "papermill": {
     "duration": 0.016415,
     "end_time": "2022-12-04T16:07:05.818450",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.802035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class PRMLDataset(Dataset):\n",
    "#     def __init__(self, df, cats, y):\n",
    "#         self.dfcats = df[cats]\n",
    "#         self.dfconts = df.drop(cats, axis=1)\n",
    "        \n",
    "#         self.cats = np.stack([c.values for n, c in self.dfcats.items()], axis=1).astype(np.int64)\n",
    "#         self.conts = np.stack([c.values for n, c in self.dfconts.items()], axis=1).astype(np.float32)\n",
    "#         self.y = y.values.astype(np.float32)\n",
    "        \n",
    "#     def __len__(self): \n",
    "#         return len(self.y)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return [self.cats[idx], self.conts[idx], self.y[idx]]\n",
    "    \n",
    "    \n",
    "class PRMLDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c1482",
   "metadata": {
    "papermill": {
     "duration": 0.010076,
     "end_time": "2022-12-04T16:07:05.834850",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.824774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173b3bb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:05.848689Z",
     "iopub.status.busy": "2022-12-04T16:07:05.848427Z",
     "iopub.status.idle": "2022-12-04T16:07:05.900003Z",
     "shell.execute_reply": "2022-12-04T16:07:05.899106Z"
    },
    "papermill": {
     "duration": 0.060899,
     "end_time": "2022-12-04T16:07:05.902254",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.841355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rating_score                                  1.059644\n",
       "booking_status                                0.334847\n",
       "country                                       2.579839\n",
       "payment_type_mode                             1.274003\n",
       "payment_type_count                            0.252964\n",
       "payment_sequential_sum                        0.815526\n",
       "payment_installments_count                    0.512525\n",
       "payment_installments_sum                      2.751797\n",
       "payment_value_count                           0.429139\n",
       "booking_sequence_id_max                       0.518593\n",
       "hotel_category_max                           22.445801\n",
       "hotel_category_count                          0.531611\n",
       "hotel_name_length_mean                        9.886931\n",
       "hotel_photos_qty_mean                         1.730230\n",
       "seller_agent_id_count                         0.532782\n",
       "booking_create_timestamp_year                 0.504744\n",
       "booking_create_timestamp_month                0.492870\n",
       "booking_create_timestamp_week                 1.480836\n",
       "booking_create_timestamp_weekday              0.498818\n",
       "booking_create_timestamp_hour                 0.000000\n",
       "booking_approved_at_year                      0.504487\n",
       "booking_approved_at_month                     3.234000\n",
       "booking_approved_at_week                     14.046628\n",
       "booking_approved_at_weekday                   2.105717\n",
       "booking_approved_at_hour                      6.586924\n",
       "booking_checkin_customer_date_year            0.498152\n",
       "booking_checkin_customer_date_month           0.494662\n",
       "booking_checkin_customer_date_week            1.480334\n",
       "booking_checkin_customer_date_weekday         0.426581\n",
       "booking_checkin_customer_date_hour            4.958920\n",
       "payment_value_sum_log2                        1.169290\n",
       "price_sum_log2                                1.452100\n",
       "agent_fees_sum_log2                           0.972766\n",
       "hotel_description_length_mean_log2            1.115274\n",
       "booking_approved_minus_created_days           0.981139\n",
       "booking_approved_minus_created_hours_log2     2.911983\n",
       "booking_checkin_minus_created_days_log2       1.028310\n",
       "booking_checkin_minus_created_hours_log2      0.987947\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb7442b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:05.917808Z",
     "iopub.status.busy": "2022-12-04T16:07:05.917517Z",
     "iopub.status.idle": "2022-12-04T16:07:06.453733Z",
     "shell.execute_reply": "2022-12-04T16:07:06.452791Z"
    },
    "papermill": {
     "duration": 0.547526,
     "end_time": "2022-12-04T16:07:06.456968",
     "exception": false,
     "start_time": "2022-12-04T16:07:05.909442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['hotel_category_max'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "288acae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:06.529845Z",
     "iopub.status.busy": "2022-12-04T16:07:06.529456Z",
     "iopub.status.idle": "2022-12-04T16:07:06.760655Z",
     "shell.execute_reply": "2022-12-04T16:07:06.759574Z"
    },
    "papermill": {
     "duration": 0.268476,
     "end_time": "2022-12-04T16:07:06.764106",
     "exception": false,
     "start_time": "2022-12-04T16:07:06.495630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df[df['set'] == 'training']\n",
    "test_df = df[df['set'] == 'testing']\n",
    "\n",
    "train_X = train_df.drop(['booking_id', 'rating_score', 'set'], axis=1)\n",
    "test_X = test_df.drop(['booking_id', 'rating_score', 'set'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "x = train_X.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "train_X = pd.DataFrame(x_scaled, columns=train_X.columns)\n",
    "\n",
    "test_X = pd.DataFrame(min_max_scaler.transform(test_X.values), columns=train_X.columns)\n",
    "\n",
    "\n",
    "train_y = train_df['rating_score']\n",
    "test_y = test_df['rating_score']\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66849a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:06.812419Z",
     "iopub.status.busy": "2022-12-04T16:07:06.811963Z",
     "iopub.status.idle": "2022-12-04T16:07:06.823530Z",
     "shell.execute_reply": "2022-12-04T16:07:06.820171Z"
    },
    "papermill": {
     "duration": 0.047087,
     "end_time": "2022-12-04T16:07:06.830831",
     "exception": false,
     "start_time": "2022-12-04T16:07:06.783744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256cf0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:06.860721Z",
     "iopub.status.busy": "2022-12-04T16:07:06.860377Z",
     "iopub.status.idle": "2022-12-04T16:07:06.882212Z",
     "shell.execute_reply": "2022-12-04T16:07:06.879558Z"
    },
    "papermill": {
     "duration": 0.038332,
     "end_time": "2022-12-04T16:07:06.884825",
     "exception": false,
     "start_time": "2022-12-04T16:07:06.846493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainds = PRMLDataset(X_train, catf, y_train)\n",
    "# valds = PRMLDataset(X_val, catf, y_val)\n",
    "# testds = PRMLDataset(test_X, catf, test_y)\n",
    "\n",
    "trainds = PRMLDataset(torch.from_numpy(X_train.values).float(), torch.from_numpy(y_train.values).float())\n",
    "valds = PRMLDataset(torch.from_numpy(X_val.values).float(), torch.from_numpy(y_val.values).float())\n",
    "testds = PRMLDataset(torch.from_numpy(test_X.values).float(), torch.from_numpy(test_y.values).float())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273a8c7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:06.907969Z",
     "iopub.status.busy": "2022-12-04T16:07:06.907646Z",
     "iopub.status.idle": "2022-12-04T16:07:06.911897Z",
     "shell.execute_reply": "2022-12-04T16:07:06.911095Z"
    },
    "papermill": {
     "duration": 0.019573,
     "end_time": "2022-12-04T16:07:06.915905",
     "exception": false,
     "start_time": "2022-12-04T16:07:06.896332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ConcatDataset([trainds, valds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45aaaa12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:06.938481Z",
     "iopub.status.busy": "2022-12-04T16:07:06.938168Z",
     "iopub.status.idle": "2022-12-04T16:07:06.963026Z",
     "shell.execute_reply": "2022-12-04T16:07:06.962196Z"
    },
    "papermill": {
     "duration": 0.039077,
     "end_time": "2022-12-04T16:07:06.965812",
     "exception": false,
     "start_time": "2022-12-04T16:07:06.926735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self,h1=96):\n",
    "#         # We optimize dropout rate in a convolutional neural network.\n",
    "#         super(ConvNet, self).__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "#         self.drop1=nn.Dropout2d(p=0.5)   \n",
    "\n",
    "#         self.fc1 = nn.Linear(32 * 7 * 7, h1)\n",
    "#         self.drop2=nn.Dropout2d(p=0.1)\n",
    "\n",
    "#         self.fc2 = nn.Linear(h1, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x),kernel_size = 2))\n",
    "\n",
    "#         x = F.relu(F.max_pool2d(self.conv2(x),kernel_size = 2))\n",
    "#         x = self.drop1(x)\n",
    "\n",
    "#         x = x.view(x.size(0),-1)\n",
    "\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.drop2(x)\n",
    "\n",
    "#         x = self.fc2(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "def reset_weights(m):\n",
    "    \"\"\"\n",
    "    Try resetting model weights to avoid weight leakage.\n",
    "    \"\"\"\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "#             print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(X_train.shape[1], 159),\n",
    "#     nn.BatchNorm1d(159),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.05),   \n",
    "    \n",
    "    \n",
    "#     nn.Linear(159, 159),\n",
    "#     nn.BatchNorm1d(159),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.15),    \n",
    "    \n",
    "#     nn.Linear(159, 100),\n",
    "#     nn.BatchNorm1d(100),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.15), \n",
    "    \n",
    "#     nn.Linear(100,1)\n",
    "# )\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(X_train.shape[1], 72),\n",
    "#     nn.BatchNorm1d(72),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.05),   \n",
    "    \n",
    "    \n",
    "#     nn.Linear(72, 72),\n",
    "#     nn.BatchNorm1d(72),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.15),    \n",
    "    \n",
    "#     nn.Linear(72, 36),\n",
    "#     nn.BatchNorm1d(36),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.15), \n",
    "    \n",
    "#     nn.Linear(36,1)\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 1000),\n",
    "    nn.BatchNorm1d(1000),\n",
    "    # nn.ReLU(),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.5),   \n",
    "    \n",
    "    \n",
    "    nn.Linear(1000, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    # nn.ReLU(),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.25),    \n",
    "    \n",
    "    nn.Linear(512,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1610805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:06.990368Z",
     "iopub.status.busy": "2022-12-04T16:07:06.989989Z",
     "iopub.status.idle": "2022-12-04T16:07:06.995824Z",
     "shell.execute_reply": "2022-12-04T16:07:06.994912Z"
    },
    "papermill": {
     "duration": 0.022736,
     "end_time": "2022-12-04T16:07:07.000218",
     "exception": false,
     "start_time": "2022-12-04T16:07:06.977482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 70\n",
    "batch_size = 5000\n",
    "k = 20\n",
    "splits = KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "114ee3f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:07.026226Z",
     "iopub.status.busy": "2022-12-04T16:07:07.025887Z",
     "iopub.status.idle": "2022-12-04T16:07:07.043067Z",
     "shell.execute_reply": "2022-12-04T16:07:07.042259Z"
    },
    "papermill": {
     "duration": 0.032557,
     "end_time": "2022-12-04T16:07:07.045807",
     "exception": false,
     "start_time": "2022-12-04T16:07:07.013250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        # optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "            # from pytorch documentation\n",
    "            \n",
    "        output = model(images)\n",
    "        loss = loss_fn(output.squeeze(),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "  \n",
    "    \n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    # print(f'reached_here')\n",
    "    for images, labels in dataloader:\n",
    "        # print(f'\\t reached_here')\n",
    "\n",
    "        images, labels = images.to(device),labels.to(device)\n",
    "        output = model(images)\n",
    "        # print(f'\\t got output')\n",
    "        loss = loss_fn(output.squeeze(),labels)\n",
    "\n",
    "        # print(f'\\t got loss')\n",
    "        valid_loss+=loss.item()*images.size(0)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        val_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return valid_loss, val_correct\n",
    "\n",
    "\n",
    "def make_preds_on_test(model, device, dataloader,loss_fn):\n",
    "    sub = []\n",
    "    test_dataloader = dataloader # DataLoader(testds, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device),labels.to(device)\n",
    "        output = model(images).detach().cpu().numpy()\n",
    "        sub.append(output)\n",
    "        \n",
    "    preds = np.concatenate(sub, axis=0 )\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f003dc11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:07:07.071174Z",
     "iopub.status.busy": "2022-12-04T16:07:07.070834Z",
     "iopub.status.idle": "2022-12-04T16:25:42.461823Z",
     "shell.execute_reply": "2022-12-04T16:25:42.460872Z"
    },
    "papermill": {
     "duration": 1115.40665,
     "end_time": "2022-12-04T16:25:42.464436",
     "exception": false,
     "start_time": "2022-12-04T16:07:07.057786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5495738857670833 \t AVG Test Loss:1.4547120332717896\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.5586402353487516 \t AVG Test Loss:1.4159061908721924\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4973244792536686 \t AVG Test Loss:1.5176365375518799\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4361338740900944 \t AVG Test Loss:1.3954493999481201\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4321022723850452 \t AVG Test Loss:1.39421808719635\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4297340543646562 \t AVG Test Loss:1.3934084177017212\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4293920868321468 \t AVG Test Loss:1.3939658403396606\n",
      "\n",
      "Fold 2\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.554714980878328 \t AVG Test Loss:1.4804505109786987\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4902414208964299 \t AVG Test Loss:1.424131155014038\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4576803508557772 \t AVG Test Loss:1.4282517433166504\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4193796295868724 \t AVG Test Loss:1.4138551950454712\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4208348173844187 \t AVG Test Loss:1.414162516593933\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4123890964608443 \t AVG Test Loss:1.4117342233657837\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4156061724612587 \t AVG Test Loss:1.4113433361053467\n",
      "\n",
      "Fold 3\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.54841621298539 \t AVG Test Loss:1.457045316696167\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4873141364047402 \t AVG Test Loss:1.466846227645874\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4523171311930607 \t AVG Test Loss:1.5332163572311401\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4234329963985242 \t AVG Test Loss:1.4012948274612427\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4185468334900706 \t AVG Test Loss:1.4011766910552979\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.41213195574911 \t AVG Test Loss:1.4012149572372437\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4154100543574284 \t AVG Test Loss:1.4014707803726196\n",
      "\n",
      "Fold 4\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5633264278110706 \t AVG Test Loss:1.518584132194519\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4847770427402698 \t AVG Test Loss:1.461685061454773\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.459559440612793 \t AVG Test Loss:1.4648196697235107\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4304843952781277 \t AVG Test Loss:1.4263759851455688\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4226280513562655 \t AVG Test Loss:1.4255638122558594\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4190393874519749 \t AVG Test Loss:1.4256280660629272\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4184206849650334 \t AVG Test Loss:1.4245017766952515\n",
      "\n",
      "Fold 5\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5548342089903981 \t AVG Test Loss:1.4028053283691406\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4804631157925254 \t AVG Test Loss:1.4159542322158813\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4573135940652144 \t AVG Test Loss:1.3888399600982666\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.431208610534668 \t AVG Test Loss:1.361348032951355\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4260253153349225 \t AVG Test Loss:1.3619153499603271\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4249363698457416 \t AVG Test Loss:1.3610904216766357\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4196923092791909 \t AVG Test Loss:1.3596910238265991\n",
      "\n",
      "Fold 6\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5508121628510325 \t AVG Test Loss:1.5172905921936035\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4853416430322748 \t AVG Test Loss:1.511143445968628\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4685565484197516 \t AVG Test Loss:1.474166989326477\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4341983983391209 \t AVG Test Loss:1.4642772674560547\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4308405989094783 \t AVG Test Loss:1.4632796049118042\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4261105625252974 \t AVG Test Loss:1.4629019498825073\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4236577874735783 \t AVG Test Loss:1.4620956182479858\n",
      "\n",
      "Fold 7\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5675366113060398 \t AVG Test Loss:1.4969377517700195\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4987585732811375 \t AVG Test Loss:1.416990041732788\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4535845769079108 \t AVG Test Loss:1.3860044479370117\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4207713541231657 \t AVG Test Loss:1.3768541812896729\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4230591937115318 \t AVG Test Loss:1.3729817867279053\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4225918054580688 \t AVG Test Loss:1.371232032775879\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4158879643992375 \t AVG Test Loss:1.3709133863449097\n",
      "\n",
      "Fold 8\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5637347949178595 \t AVG Test Loss:1.429131269454956\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4889734230543439 \t AVG Test Loss:1.4238165616989136\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4500295551199662 \t AVG Test Loss:1.418560266494751\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4220448669634367 \t AVG Test Loss:1.3879101276397705\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4200246710526316 \t AVG Test Loss:1.3841661214828491\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.420005020342375 \t AVG Test Loss:1.384137511253357\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4215633367237293 \t AVG Test Loss:1.3832460641860962\n",
      "\n",
      "Fold 9\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5442274369691547 \t AVG Test Loss:1.471980094909668\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4906459795801263 \t AVG Test Loss:1.4364094734191895\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4563883103822406 \t AVG Test Loss:1.418057918548584\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4223114377573918 \t AVG Test Loss:1.388916254043579\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4221315823103253 \t AVG Test Loss:1.3884105682373047\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4184863379127102 \t AVG Test Loss:1.3881181478500366\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.415698107920195 \t AVG Test Loss:1.3865097761154175\n",
      "\n",
      "Fold 10\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.562348290493614 \t AVG Test Loss:1.4373223781585693\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4964630980240672 \t AVG Test Loss:1.3640296459197998\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4530370047217922 \t AVG Test Loss:1.4018011093139648\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4335574288117259 \t AVG Test Loss:1.3545469045639038\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.434859225624486 \t AVG Test Loss:1.3547639846801758\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.42659372405002 \t AVG Test Loss:1.354499101638794\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4238322283092297 \t AVG Test Loss:1.3534435033798218\n",
      "\n",
      "Fold 11\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5444270121423822 \t AVG Test Loss:1.4621145725250244\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.5047310277035362 \t AVG Test Loss:1.439365029335022\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.459219449444821 \t AVG Test Loss:1.4116389751434326\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4232837338196604 \t AVG Test Loss:1.4020955562591553\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4189470692684776 \t AVG Test Loss:1.3998820781707764\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4205853186155621 \t AVG Test Loss:1.4000990390777588\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4126449886121248 \t AVG Test Loss:1.3986694812774658\n",
      "\n",
      "Fold 12\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.554211647886979 \t AVG Test Loss:1.4502650499343872\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4919441248241223 \t AVG Test Loss:1.4407885074615479\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.448796504422238 \t AVG Test Loss:1.4207282066345215\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4219188000026501 \t AVG Test Loss:1.4091370105743408\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4165452530509548 \t AVG Test Loss:1.4077659845352173\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4195332464418913 \t AVG Test Loss:1.4072118997573853\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4217148580049213 \t AVG Test Loss:1.4063111543655396\n",
      "\n",
      "Fold 13\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5488891350595575 \t AVG Test Loss:1.4830609560012817\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.478116317799217 \t AVG Test Loss:1.4641313552856445\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4604486728969372 \t AVG Test Loss:1.4839305877685547\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.419824110834222 \t AVG Test Loss:1.4359132051467896\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4138226446352506 \t AVG Test Loss:1.4361977577209473\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4124246020066111 \t AVG Test Loss:1.436578392982483\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4125506062256663 \t AVG Test Loss:1.436847448348999\n",
      "\n",
      "Fold 14\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5454923479180587 \t AVG Test Loss:1.539750099182129\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4978145737397044 \t AVG Test Loss:1.4993177652359009\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4442281911247654 \t AVG Test Loss:1.4341760873794556\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4256811643901623 \t AVG Test Loss:1.4245470762252808\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4235447017770064 \t AVG Test Loss:1.4236607551574707\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4243784389997785 \t AVG Test Loss:1.4217654466629028\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4208084595830817 \t AVG Test Loss:1.42245614528656\n",
      "\n",
      "Fold 15\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5659944132754677 \t AVG Test Loss:1.4814289808273315\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.493004560470581 \t AVG Test Loss:1.411731243133545\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4524802345978587 \t AVG Test Loss:1.3956910371780396\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.426347996059217 \t AVG Test Loss:1.3816114664077759\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4195984413749294 \t AVG Test Loss:1.3838690519332886\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.422875071826734 \t AVG Test Loss:1.3809301853179932\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4188299681010998 \t AVG Test Loss:1.3779146671295166\n",
      "\n",
      "Fold 16\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5581234505302028 \t AVG Test Loss:1.4306120872497559\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4890891376294588 \t AVG Test Loss:1.3843671083450317\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4476753222314935 \t AVG Test Loss:1.3697166442871094\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4337705499247502 \t AVG Test Loss:1.3624873161315918\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4319838724638287 \t AVG Test Loss:1.3608033657073975\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4274421302895797 \t AVG Test Loss:1.360119342803955\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4186668145029169 \t AVG Test Loss:1.3614627122879028\n",
      "\n",
      "Fold 17\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5661319807956093 \t AVG Test Loss:1.4079139232635498\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4927693228972585 \t AVG Test Loss:1.4156886339187622\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.47735007185685 \t AVG Test Loss:1.37470543384552\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4342889158349288 \t AVG Test Loss:1.3380149602890015\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.435485695537768 \t AVG Test Loss:1.3384054899215698\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4327724921075922 \t AVG Test Loss:1.3381569385528564\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4288151766124524 \t AVG Test Loss:1.3377740383148193\n",
      "\n",
      "Fold 18\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.5674891032670673 \t AVG Test Loss:1.4001673460006714\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.5359198607896503 \t AVG Test Loss:1.4465118646621704\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4694592074344033 \t AVG Test Loss:1.4199600219726562\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4341117771048295 \t AVG Test Loss:1.3356913328170776\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.430298554269891 \t AVG Test Loss:1.3367505073547363\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4296855550063283 \t AVG Test Loss:1.3368754386901855\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4240585942017405 \t AVG Test Loss:1.3363368511199951\n",
      "\n",
      "Fold 19\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.546858549118042 \t AVG Test Loss:1.405861735343933\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4906766100933677 \t AVG Test Loss:1.3889033794403076\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4769980970181917 \t AVG Test Loss:1.369617223739624\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.4283540562579506 \t AVG Test Loss:1.3701977729797363\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4295912667324668 \t AVG Test Loss:1.3686623573303223\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.428729722374364 \t AVG Test Loss:1.3674041032791138\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4266288594195717 \t AVG Test Loss:1.3693013191223145\n",
      "\n",
      "Fold 20\n",
      "Epoch:10/70, lr = 0.01 , AVG Training Loss:1.559154893222608 \t AVG Test Loss:1.5230145454406738\n",
      "Epoch:20/70, lr = 0.01 , AVG Training Loss:1.4907118834947284 \t AVG Test Loss:1.4803003072738647\n",
      "Epoch:30/70, lr = 0.01 , AVG Training Loss:1.4553137076528448 \t AVG Test Loss:1.4567172527313232\n",
      "Epoch:40/70, lr = 0.0001 , AVG Training Loss:1.425341336350692 \t AVG Test Loss:1.4315086603164673\n",
      "Epoch:50/70, lr = 0.0001 , AVG Training Loss:1.4245181460129588 \t AVG Test Loss:1.4308223724365234\n",
      "Epoch:60/70, lr = 0.0001 , AVG Training Loss:1.4205319567730552 \t AVG Test Loss:1.4284900426864624\n",
      "Epoch:70/70, lr = 0.0001 , AVG Training Loss:1.4178232895700555 \t AVG Test Loss:1.4298304319381714\n"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "sub = []\n",
    "test_dataloader = DataLoader(testds, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('\\nFold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "    model = model\n",
    "    model.apply(reset_weights)\n",
    "    model.to(device)\n",
    "\n",
    "    # for the first 70% of epochs\n",
    "    # train like 70% of epochs have lr = 0.0001\n",
    "    # rest 30% have lr = 1e-6\n",
    "    frac = 0.5\n",
    "    lr1 = 1e-2\n",
    "    lr2 = 1e-4\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr1, weight_decay= 0.00001)\n",
    "    for epoch in range(int(frac * num_epochs)):\n",
    "        train_loss, train_correct = train_epoch(model,device,train_loader,criterion,optimizer)        \n",
    "        val_loss, test_correct = valid_epoch(model,device,val_loader,criterion)\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        val_loss = val_loss / len(val_loader.sampler)\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f\"Epoch:{epoch + 1}/{num_epochs}, lr = {lr1} , AVG Training Loss:{train_loss} \\t AVG Test Loss:{val_loss}\")\n",
    "    \n",
    "    optimizer2 = optim.Adam(model.parameters(), lr = lr2, weight_decay= 0.00001)\n",
    "    for epoch in range(int(frac * num_epochs), num_epochs):\n",
    "        train_loss, train_correct = train_epoch(model,device,train_loader,criterion,optimizer2)        \n",
    "        val_loss, test_correct = valid_epoch(model,device,val_loader,criterion)\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        val_loss = val_loss / len(val_loader.sampler)\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f\"Epoch:{epoch + 1}/{num_epochs}, lr = {lr2} , AVG Training Loss:{train_loss} \\t AVG Test Loss:{val_loss}\")\n",
    "    \n",
    "    \n",
    "    preds = make_preds_on_test(model, device, test_dataloader, criterion)\n",
    "    sub.append(preds)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['test_loss'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f1c36",
   "metadata": {
    "papermill": {
     "duration": 0.014499,
     "end_time": "2022-12-04T16:25:42.494568",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.480069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ef7036a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:25:42.526980Z",
     "iopub.status.busy": "2022-12-04T16:25:42.526608Z",
     "iopub.status.idle": "2022-12-04T16:25:42.532633Z",
     "shell.execute_reply": "2022-12-04T16:25:42.531663Z"
    },
    "papermill": {
     "duration": 0.024807,
     "end_time": "2022-12-04T16:25:42.534835",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.510028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of 20 fold cross validation\n",
      "Average Training Loss: 1.420085117377733 Average Test Loss: 1.3912042677402496\n"
     ]
    }
   ],
   "source": [
    "avg_train_loss = np.mean(history['train_loss'])\n",
    "avg_test_loss = np.mean(history['test_loss'])\n",
    "\n",
    "\n",
    "print(f'Performance of {k} fold cross validation')\n",
    "print(f\"Average Training Loss: {avg_train_loss} Average Test Loss: {avg_test_loss}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8320422b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:25:42.565950Z",
     "iopub.status.busy": "2022-12-04T16:25:42.565692Z",
     "iopub.status.idle": "2022-12-04T16:25:42.572979Z",
     "shell.execute_reply": "2022-12-04T16:25:42.572033Z"
    },
    "papermill": {
     "duration": 0.025195,
     "end_time": "2022-12-04T16:25:42.574897",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.549702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 49079)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub), len(sub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1985e7f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:25:42.605488Z",
     "iopub.status.busy": "2022-12-04T16:25:42.605233Z",
     "iopub.status.idle": "2022-12-04T16:25:42.611049Z",
     "shell.execute_reply": "2022-12-04T16:25:42.610117Z"
    },
    "papermill": {
     "duration": 0.023121,
     "end_time": "2022-12-04T16:25:42.612939",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.589818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30f090c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:25:42.644087Z",
     "iopub.status.busy": "2022-12-04T16:25:42.643351Z",
     "iopub.status.idle": "2022-12-04T16:25:42.653663Z",
     "shell.execute_reply": "2022-12-04T16:25:42.652619Z"
    },
    "papermill": {
     "duration": 0.028223,
     "end_time": "2022-12-04T16:25:42.655822",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.627599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.105613 , 4.2706347, 4.489377 , ..., 4.216469 , 4.003313 ,\n",
       "       4.532056 ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(sub).reshape(k,-1)\n",
    "preds = np.mean(arr, axis = 0)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29d32ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:25:42.687397Z",
     "iopub.status.busy": "2022-12-04T16:25:42.687138Z",
     "iopub.status.idle": "2022-12-04T16:25:42.872069Z",
     "shell.execute_reply": "2022-12-04T16:25:42.871166Z"
    },
    "papermill": {
     "duration": 0.203098,
     "end_time": "2022-12-04T16:25:42.874559",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.671461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('/kaggle/input/datacon-22/Processed_data/sample_submission_5.csv')\n",
    "sample_sub.rating_score = preds\n",
    "sample_sub.to_csv('submission_new_Archi-kfoldmodel-20_fold_finetune-loss_1_3365-1_3823.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33644061",
   "metadata": {
    "papermill": {
     "duration": 0.014747,
     "end_time": "2022-12-04T16:25:42.904995",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.890248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a63ae8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:25:42.942315Z",
     "iopub.status.busy": "2022-12-04T16:25:42.941317Z",
     "iopub.status.idle": "2022-12-04T16:25:42.957477Z",
     "shell.execute_reply": "2022-12-04T16:25:42.955193Z"
    },
    "papermill": {
     "duration": 0.039966,
     "end_time": "2022-12-04T16:25:42.960579",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.920613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # make predictions\n",
    "# # note that this is like training with last k-fold wala model only\n",
    "\n",
    "# sub = []\n",
    "# test_dataloader = DataLoader(testds, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "# for images, labels in test_dataloader = DataLoader(testds, batch_size=batch_size, shuffle = False):\n",
    "#     images, labels = images.to(device),labels.to(device)\n",
    "#     output = model(images).detach().cpu().numpy()\n",
    "#     sub.append(output)\n",
    "    \n",
    "# preds = np.concatenate(sub, axis=0 )\n",
    "# sub = pd.read_csv('/kaggle/input/datacon-22/Processed_data/sample_submission_5.csv')\n",
    "# sub.rating_score = preds\n",
    "# sub.to_csv('submission_kfoldmodel-loss_1_4201-1_3958.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f824d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T16:25:43.005668Z",
     "iopub.status.busy": "2022-12-04T16:25:43.005356Z",
     "iopub.status.idle": "2022-12-04T16:25:43.009710Z",
     "shell.execute_reply": "2022-12-04T16:25:43.008704Z"
    },
    "papermill": {
     "duration": 0.022512,
     "end_time": "2022-12-04T16:25:43.011697",
     "exception": false,
     "start_time": "2022-12-04T16:25:42.989185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a255473",
   "metadata": {
    "papermill": {
     "duration": 0.014577,
     "end_time": "2022-12-04T16:25:43.041642",
     "exception": false,
     "start_time": "2022-12-04T16:25:43.027065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35167826",
   "metadata": {
    "papermill": {
     "duration": 0.01458,
     "end_time": "2022-12-04T16:25:43.071016",
     "exception": false,
     "start_time": "2022-12-04T16:25:43.056436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1136.631231,
   "end_time": "2022-12-04T16:25:45.511335",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-04T16:06:48.880104",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
